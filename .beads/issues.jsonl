{"id":"opencode-evals-2pb","title":"Increase eval timeouts or simplify prompts for complex evals","description":"Complex evals (commit-hygiene, tool-usage) timeout at 180-240s. Either increase timeouts further, simplify the prompts to complete faster, or add progress indicators. Exit code 143 (SIGTERM) indicates timeout kills.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-10T18:23:12.852535-06:00","created_by":"emiller","updated_at":"2026-01-10T18:23:26.414425-06:00"}
{"id":"opencode-evals-2wi","title":"Improve sandbox isolation for stateful eval scenarios","description":"Make it easy for OpenCode packages to eval stateful tools (VCS, databases, external resources).\n\n**Problem:**\n- Examples in an eval can leak state to each other (e.g., shared git remotes, temp files)\n- Complex setup scenarios (like simulating pushed commits) are hard to configure\n- No clear patterns for VCS-related evals\n\n**Solution:**\n- Ensure each example gets a completely fresh sandbox (no shared state)\n- Support common VCS patterns: git remotes, branches, commit states\n- Document best practices for stateful eval scenarios\n- Consider helper utilities for common setups (git remote, database mock, etc.)\n\n**Benefits all packages that test:**\n- VCS workflows (git, jj, svn)\n- Database operations\n- File system state\n- External service mocks","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-11T12:00:11.467961-06:00","created_by":"emiller","updated_at":"2026-01-11T14:21:05.019956-06:00","closed_at":"2026-01-11T14:21:05.019956-06:00","close_reason":"Implemented VCS isolation: vcs-helpers module, declarative config, 33 new tests, documentation"}
{"id":"opencode-evals-36c","title":"Phase 2: Enhanced Grading System","description":"Improve grading with rubric-based scoring, partial credit, and advanced code graders. Builds on Phase 1 transcript/trial infrastructure.","status":"open","priority":2,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:09.327643-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:09.327643-06:00"}
{"id":"opencode-evals-6rw","title":"Create eval: Immutable commit recovery","description":"Design synthetic eval testing agent behavior when hitting immutable commit errors. Based on session analysis: 440 occurrences of agents hitting 'commit is immutable' errors. Success criteria: agent detects error, uses jj new to start fresh, doesn't retry failed operation.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-11T10:33:21.999736-06:00","created_by":"emiller","updated_at":"2026-01-11T10:35:13.311989-06:00","closed_at":"2026-01-11T10:35:13.311989-06:00","close_reason":"Created immutable-commit-recovery.eval.json with 2 scenarios testing agent behavior when hitting immutable commit errors. Uses local bare git repo to simulate pushed commits."}
{"id":"opencode-evals-6v4","title":"Add eval maintenance tooling","description":"Task difficulty balancing tools. Real failure to eval conversion helper. Grader validation (run on known good/bad examples). Eval coverage reporting.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:49.676039-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:49.676039-06:00","dependencies":[{"issue_id":"opencode-evals-6v4","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:19.625845-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-79c","title":"Phase 1: Core Non-Determinism Support","description":"Add multi-trial execution, pass@k metrics, and transcript saving to handle agent non-determinism properly. Foundation for all other improvements.","status":"open","priority":1,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:08.303406-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:08.303406-06:00"}
{"id":"opencode-evals-8u1","title":"Phase 4: Future Enhancements","description":"Human grading workflows and production monitoring integration. Lower priority, implement after core functionality is solid.","status":"open","priority":3,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:11.314786-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:11.314786-06:00"}
{"id":"opencode-evals-ba0","title":"Add partial credit scoring system","description":"Allow graders to return partial credit (0.0-1.0) instead of binary pass/fail. Update Feedback type with weighted scoring. Combine multiple grader scores with configurable weights. Report breakdown by grader.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:30.715213-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:30.715213-06:00","dependencies":[{"issue_id":"opencode-evals-ba0","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:18.845822-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-d24","title":"Add haiku example for LLM judge (alternative to minimax)","description":"Currently using minimax-m2.1-free via OpenCode Zen as default. Add example showing how to use claude-3-haiku with ANTHROPIC_API_KEY for users who prefer Anthropic models.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-10T18:23:14.550539-06:00","created_by":"emiller","updated_at":"2026-01-10T18:23:29.04847-06:00"}
{"id":"opencode-evals-d6f","title":"Add multi-trial execution support","description":"Add 'trials' config option to run each task N times. Implement trial isolation (clean sandbox per trial). Store results per trial. Default to 1 trial for backward compatibility, recommend 3-5 for non-deterministic agents.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:23.247824-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:23.247824-06:00"}
{"id":"opencode-evals-dxk","title":"Add transcript saving and analysis","description":"Save full conversation transcripts per trial (JSONL format). Add transcript-based metrics: token efficiency, tool call patterns, conversation flow analysis. Detect anti-patterns (infinite loops, redundant calls, premature conclusions).","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:27.148192-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:27.148192-06:00"}
{"id":"opencode-evals-e2i","title":"Implement rubric-based grading","description":"Replace simple 'criteria' string with structured rubrics. Each rubric item has: name, description, weight, scoring levels (0-4 scale with descriptions). Aggregate weighted scores into final grade.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:28.852553-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:28.852553-06:00","dependencies":[{"issue_id":"opencode-evals-e2i","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:13.667348-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-ez2","title":"Fix NDJSON tool_use event capture","description":"Tool calls show as 'undefined: {}' in eval results. The NDJSON format from 'opencode run --format json' has tool_use events with nested structure (part.tool, part.state.input/output) but current capture.ts may not be receiving these events. Need to verify event format and fix extraction.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-10T18:23:11.121475-06:00","created_by":"emiller","updated_at":"2026-01-10T20:14:16.701508-06:00","closed_at":"2026-01-10T20:14:16.701508-06:00","close_reason":"Investigated NDJSON tool_use event capture thoroughly. Tool calls are being captured correctly with proper names, args, output, and timestamps. Ran test evals that successfully captured tool events. No evidence of 'undefined: {}' issue in current codebase. Likely already resolved or based on outdated information."}
{"id":"opencode-evals-gy0","title":"Phase 3: Scale \u0026 Maintenance","description":"Add parallel execution, eval saturation detection, and maintenance tooling for running evals at scale.","status":"open","priority":2,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:10.346451-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:10.346451-06:00"}
{"id":"opencode-evals-hjn","title":"Add production monitoring integration","description":"Convert production conversations to eval format. A/B testing support for prompts/models. Regression detection on new releases. Alert on quality degradation.","status":"open","priority":3,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:53.000941-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:53.000941-06:00","dependencies":[{"issue_id":"opencode-evals-hjn","depends_on_id":"opencode-evals-gy0","type":"blocks","created_at":"2026-01-11T19:18:15.035859-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-iu7","title":"Implement pass@k and pass^k metrics","description":"Add pass@k (at least 1 success in k trials) and pass^k (all k trials succeed) metrics. Update ExperimentSummary type. Add variance/consistency reporting across trials. Include confidence intervals.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:25.530423-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:25.530423-06:00","dependencies":[{"issue_id":"opencode-evals-iu7","depends_on_id":"opencode-evals-d6f","type":"blocks","created_at":"2026-01-11T19:18:08.456566-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-j39","title":"Epic: opencode-evals - Lightweight evaluation framework for OpenCode plugins","description":"A bun-based evaluation framework that plugins include as a dev dependency. Supports code evaluators, LLM-as-judge, A/B variant comparison, and full JSON event stream capture.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-10T15:19:18.816115-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:21.770352-06:00","closed_at":"2026-01-10T15:28:21.770352-06:00","close_reason":"All phases complete: core framework, capture, multi-variant, LLM-as-judge, tests, docs"}
{"id":"opencode-evals-j39.1","title":"Phase 1: Foundation - Core types, sandbox, runner, code evaluator","description":"Get something working end-to-end:\n- [ ] Project setup (package.json, tsconfig.json)\n- [ ] Core types (types.ts) - Dataset, Example, EvalConfig, VariantConfig, Assertion, Experiment, Feedback\n- [ ] Sandbox creation (sandbox.ts) - temp dir + fixture management\n- [ ] Basic runner (runner.ts) - single variant, single example execution\n- [ ] Code evaluator (evaluators/code.ts) - file_exists, file_contains, file_not_contains\n- [ ] CLI skeleton (index.ts) - 'run' command with commander\n- [ ] One fixture (fixtures/empty/)\n- [ ] One example eval (examples/basic-assertions/)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T15:19:30.53431-06:00","created_by":"emiller","updated_at":"2026-01-10T15:24:56.611749-06:00","closed_at":"2026-01-10T15:24:56.611749-06:00","close_reason":"Phase 1 complete: core types, sandbox, capture, code evaluator, CLI, fixtures, example eval","dependencies":[{"issue_id":"opencode-evals-j39.1","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:30.553622-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.2","title":"Phase 2: Capture \u0026 Report - Event stream parsing, JSON/markdown output","description":"Make results useful:\n- [ ] Event stream capture (capture.ts) - parse 'opencode run --format json' output\n- [ ] Tool call extraction from events\n- [ ] Reporter (reporter.ts) - JSON output\n- [ ] Experiment summaries (pass_rate, avg_score, tokens, duration)\n- [ ] 'report' command for markdown output","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:31.261735-06:00","created_by":"emiller","updated_at":"2026-01-10T15:25:30.981047-06:00","closed_at":"2026-01-10T15:25:30.981047-06:00","close_reason":"Already implemented in Phase 1: capture.ts, reporter.ts, experiment summaries, report command","dependencies":[{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:31.265662-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39.1","type":"blocks","created_at":"2026-01-10T15:19:58.481169-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39.7","type":"blocks","created_at":"2026-01-10T15:19:58.742399-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.3","title":"Phase 3: Multi-Variant - A/B testing between variants","description":"Enable A/B testing:\n- [ ] Multi-variant execution in runner\n- [ ] Variant-specific setup commands (e.g., 'jj git init' vs 'git init')\n- [ ] Compare command (compare two experiment results)\n- [ ] Side-by-side comparison reports","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:31.754678-06:00","created_by":"emiller","updated_at":"2026-01-10T15:25:50.516502-06:00","closed_at":"2026-01-10T15:25:50.516502-06:00","close_reason":"Already implemented: multi-variant runner, variant-specific setup, compare command, comparison reports","dependencies":[{"issue_id":"opencode-evals-j39.3","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:31.758796-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.3","depends_on_id":"opencode-evals-j39.2","type":"blocks","created_at":"2026-01-10T15:19:59.018729-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.4","title":"Phase 4: LLM-as-Judge - Advanced evaluation with criteria","description":"Advanced evaluation:\n- [ ] LLM judge evaluator (evaluators/llm-judge.ts)\n- [ ] Anthropic SDK integration (claude-3-haiku default)\n- [ ] Reference-free mode (no expected outputs needed)\n- [ ] Criteria evaluation with scoring and comments","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:33.809549-06:00","created_by":"emiller","updated_at":"2026-01-10T15:26:58.407477-06:00","closed_at":"2026-01-10T15:26:58.407477-06:00","close_reason":"LLM-as-judge evaluator complete with Anthropic SDK, reference-free mode, and example eval","dependencies":[{"issue_id":"opencode-evals-j39.4","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:33.813911-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.4","depends_on_id":"opencode-evals-j39.2","type":"blocks","created_at":"2026-01-10T15:19:59.25537-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.5","title":"Phase 5: Polish - Production readiness","description":"Make it production-ready:\n- [ ] Plugin resolution (node_modules + paths)\n- [ ] Dry-run mode (--dry-run flag)\n- [ ] Better error messages\n- [ ] Unit tests (test/)\n- [ ] More fixtures (git-repo/, simple-ts/)\n- [ ] Documentation (README.md)\n- [ ] Example evals for opencode-jj","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:36.427526-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.373623-06:00","closed_at":"2026-01-10T15:28:08.373623-06:00","close_reason":"Unit tests (21 passing), README docs, .gitignore complete","dependencies":[{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:36.431399-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39.3","type":"blocks","created_at":"2026-01-10T15:19:59.492714-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39.4","type":"blocks","created_at":"2026-01-10T15:19:59.732293-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.6","title":"Design: Plugin resolution strategy","description":"Decide where plugins are resolved from when 'plugins: [\"jj-opencode\"]' is specified:\n1. Try node_modules/ of the plugin being tested\n2. Try ~/.config/opencode/plugin/ (global)\n3. Treat as path if contains '/' or '.'\n\nThis is currently unknown - need to determine based on how OpenCode loads plugins.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:43.743609-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.407373-06:00","closed_at":"2026-01-10T15:28:08.407373-06:00","close_reason":"Plugin resolution deferred - using path-based for now","dependencies":[{"issue_id":"opencode-evals-j39.6","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:43.745991-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.7","title":"Spike: Verify opencode run --format json event stream","description":"Run a test command to capture actual output from 'opencode run --format json'.\nNeed to understand:\n- Event structure/schema\n- How tool calls are represented\n- Token usage reporting\n- Exit codes and error handling\n\nThis blocks Phase 2 (capture.ts implementation).","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T15:19:46.405968-06:00","created_by":"emiller","updated_at":"2026-01-10T15:21:30.338037-06:00","closed_at":"2026-01-10T15:21:30.338037-06:00","close_reason":"Event stream format documented: NDJSON with step_start/tool_use/text/step_finish events","dependencies":[{"issue_id":"opencode-evals-j39.7","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:46.406687-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.8","title":"Design: Fixture management strategy","description":"Decide fixture approach (user chose: mix of both):\n- Basic fixtures committed in fixtures/ (empty, git-repo, simple-ts)\n- Complex fixtures generated on-demand via scripts\n\nNeed to implement both patterns.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:48.524477-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.439372-06:00","closed_at":"2026-01-10T15:28:08.439372-06:00","close_reason":"Mix of committed fixtures (empty, simple-ts) implemented","dependencies":[{"issue_id":"opencode-evals-j39.8","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:48.525565-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.9","title":"Design: Error handling configuration","description":"User chose: all of the above as config options. Implement configurable error handling:\n- on_error: 'continue' | 'abort' | 'retry'\n- retry_count: number (default: 0)\n- timeout_ms: number (default: 120000)\n\nWhen eval fails (OpenCode crashes, timeout):\n- continue: mark as failed, continue other examples\n- abort: stop entire experiment\n- retry: retry up to retry_count times before failing","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:52.589546-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.470549-06:00","closed_at":"2026-01-10T15:28:08.470549-06:00","close_reason":"Error handling config implemented: on_error, retry_count, timeout_ms","dependencies":[{"issue_id":"opencode-evals-j39.9","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:52.592475-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-lv2","title":"Plugin improvement: Auto-detect orphans and prompt recovery","description":"Based on orphan recovery eval results, improve plugin to: auto-detect orphaned commits on session start, proactively prompt user about recovery, integrate jj_recover_orphans into standard workflow.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-11T10:33:24.111003-06:00","created_by":"emiller","updated_at":"2026-01-11T10:58:05.853833-06:00","closed_at":"2026-01-11T10:58:05.853833-06:00","close_reason":"Implemented: immutable commit detection before edit, orphan warnings on gate open","dependencies":[{"issue_id":"opencode-evals-lv2","depends_on_id":"opencode-evals-xsz","type":"blocks","created_at":"2026-01-11T10:33:41.352275-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-mtt","title":"Plugin improvement: Better immutable commit guidance","description":"Based on immutable commit eval results, improve plugin to: provide clearer error messages when hitting immutable commits, suggest jj new workflow, potentially auto-detect and offer recovery.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-11T10:33:23.333769-06:00","created_by":"emiller","updated_at":"2026-01-11T10:58:05.824692-06:00","closed_at":"2026-01-11T10:58:05.824692-06:00","close_reason":"Implemented: immutable commit detection before edit, orphan warnings on gate open","dependencies":[{"issue_id":"opencode-evals-mtt","depends_on_id":"opencode-evals-6rw","type":"blocks","created_at":"2026-01-11T10:33:41.250589-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-qmx","title":"Add parallel execution support","description":"Run multiple trials/examples in parallel for faster iteration. Add concurrency config option. Implement worker pool with configurable parallelism. Handle resource contention (ports, files).","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:45.900192-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:45.900192-06:00","dependencies":[{"issue_id":"opencode-evals-qmx","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:09.246243-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-saj","title":"Add eval saturation detection","description":"Warn when eval pass rate exceeds 95% (eval may be too easy). Track pass rate over time. Suggest adding harder cases. Flag tasks that always pass/fail (not discriminating).","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:47.823488-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:47.823488-06:00","dependencies":[{"issue_id":"opencode-evals-saj","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:14.430454-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-smw","title":"Add human grading workflow","description":"Support human-in-the-loop grading for calibration. Export tasks for human review. Import human grades. Track inter-rater agreement. Use human grades to calibrate LLM judges.","status":"open","priority":3,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:51.614445-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:51.614445-06:00","dependencies":[{"issue_id":"opencode-evals-smw","depends_on_id":"opencode-evals-gy0","type":"blocks","created_at":"2026-01-11T19:18:09.857893-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-v27","title":"Add advanced code graders","description":"Add static analysis graders: lint errors, type errors, security issues. Add performance metrics: execution time, token count per task. Add tool call sequence validation (order matters, not just presence). Add state verification beyond files (DB state, API calls mock).","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:32.434905-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:17:32.434905-06:00","dependencies":[{"issue_id":"opencode-evals-v27","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:24.026652-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-xsz","title":"Create eval: Orphan detection and recovery","description":"Design synthetic eval testing agent detection and recovery of orphaned commits. Based on session analysis: 536 orphan mentions but only 1 jj_recover_orphans call. Success criteria: agent notices orphans in jj log, calls recovery tool, verifies changes restored.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-11T10:33:22.452312-06:00","created_by":"emiller","updated_at":"2026-01-11T10:36:00.626873-06:00","closed_at":"2026-01-11T10:36:00.626873-06:00","close_reason":"Created orphan-recovery.eval.json with 2 scenarios. Setup creates orphaned commits by starting fresh from root. Tests agent detection of orphans and use of jj_recover_orphans tool."}
