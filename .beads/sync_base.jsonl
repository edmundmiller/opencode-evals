{"id":"opencode-evals-082","title":"Add preset evaluators for agent types","description":"Create src/presets/ with configurations for: coding-agent (unit tests + code quality rubrics), conversational-agent (empathy + clarity rubrics), research-agent (groundedness + coverage rubrics). Export from index for easy import in eval configs.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:22.034388-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:22.034388-06:00","dependencies":[{"issue_id":"opencode-evals-082","depends_on_id":"opencode-evals-bpj","type":"blocks","created_at":"2026-01-11T20:51:37.332579-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-1wo","title":"Add adaptive parallel stagger","description":"Improve parallel execution to adapt stagger delay based on error rates. If API rate limits detected, exponentially back off. Increase default stagger from 100ms to 500ms. Add --stagger flag to override. Document rate limit best practices in README.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:40.376834-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:40.376834-06:00","dependencies":[{"issue_id":"opencode-evals-1wo","depends_on_id":"opencode-evals-ac9","type":"blocks","created_at":"2026-01-11T20:52:04.564826-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-2pb","title":"Increase eval timeouts or simplify prompts for complex evals","description":"Complex evals (commit-hygiene, tool-usage) timeout at 180-240s. Either increase timeouts further, simplify the prompts to complete faster, or add progress indicators. Exit code 143 (SIGTERM) indicates timeout kills.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-10T18:23:12.852535-06:00","created_by":"emiller","updated_at":"2026-01-10T18:23:26.414425-06:00"}
{"id":"opencode-evals-2wi","title":"Improve sandbox isolation for stateful eval scenarios","description":"Make it easy for OpenCode packages to eval stateful tools (VCS, databases, external resources).\n\n**Problem:**\n- Examples in an eval can leak state to each other (e.g., shared git remotes, temp files)\n- Complex setup scenarios (like simulating pushed commits) are hard to configure\n- No clear patterns for VCS-related evals\n\n**Solution:**\n- Ensure each example gets a completely fresh sandbox (no shared state)\n- Support common VCS patterns: git remotes, branches, commit states\n- Document best practices for stateful eval scenarios\n- Consider helper utilities for common setups (git remote, database mock, etc.)\n\n**Benefits all packages that test:**\n- VCS workflows (git, jj, svn)\n- Database operations\n- File system state\n- External service mocks","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-11T12:00:11.467961-06:00","created_by":"emiller","updated_at":"2026-01-11T14:21:05.019956-06:00","closed_at":"2026-01-11T14:21:05.019956-06:00","close_reason":"Implemented VCS isolation: vcs-helpers module, declarative config, 33 new tests, documentation"}
{"id":"opencode-evals-36c","title":"Phase 2: Enhanced Grading System","description":"Improve grading with rubric-based scoring, partial credit, and advanced code graders. Builds on Phase 1 transcript/trial infrastructure.","status":"closed","priority":2,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:09.327643-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:41:15.663718-06:00","closed_at":"2026-01-11T19:41:15.663718-06:00","close_reason":"Phase 2 complete: rubric grading, partial credit, advanced evaluators"}
{"id":"opencode-evals-6rw","title":"Create eval: Immutable commit recovery","description":"Design synthetic eval testing agent behavior when hitting immutable commit errors. Based on session analysis: 440 occurrences of agents hitting 'commit is immutable' errors. Success criteria: agent detects error, uses jj new to start fresh, doesn't retry failed operation.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-11T10:33:21.999736-06:00","created_by":"emiller","updated_at":"2026-01-11T10:35:13.311989-06:00","closed_at":"2026-01-11T10:35:13.311989-06:00","close_reason":"Created immutable-commit-recovery.eval.json with 2 scenarios testing agent behavior when hitting immutable commit errors. Uses local bare git repo to simulate pushed commits."}
{"id":"opencode-evals-6v4","title":"Add eval maintenance tooling","description":"Task difficulty balancing tools. Real failure to eval conversion helper. Grader validation (run on known good/bad examples). Eval coverage reporting.","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:49.676039-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:56:48.373382-06:00","closed_at":"2026-01-11T19:56:48.373382-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-6v4","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:19.625845-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-79c","title":"Phase 1: Core Non-Determinism Support","description":"Add multi-trial execution, pass@k metrics, and transcript saving to handle agent non-determinism properly. Foundation for all other improvements.","status":"closed","priority":1,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:08.303406-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:34:11.897273-06:00","closed_at":"2026-01-11T19:34:11.897273-06:00","close_reason":"Phase 1 complete: multi-trial, transcripts, pass@k/pass^k metrics"}
{"id":"opencode-evals-7mh","title":"Enhanced production log parsing","description":"Improve parseProductionLogs with: (1) Log schema validation, (2) Support multiple log versions, (3) Extract OpenCode-specific events (context pruning, delegation, token usage). Add proper error handling for malformed logs. Document expected log format.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:42.71752-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:42.71752-06:00","dependencies":[{"issue_id":"opencode-evals-7mh","depends_on_id":"opencode-evals-ac9","type":"blocks","created_at":"2026-01-11T20:52:04.673651-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-8u1","title":"Phase 4: Future Enhancements","description":"Human grading workflows and production monitoring integration. Lower priority, implement after core functionality is solid.","status":"closed","priority":3,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:11.314786-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:41:49.121598-06:00","closed_at":"2026-01-11T20:41:49.121598-06:00","close_reason":"Phase 4 complete: human grading workflow and production monitoring"}
{"id":"opencode-evals-9p7","title":"Configurable health score weights","description":"Expose health score formula weights as config (currently hardcoded: 15% per saturation warning, 30% grader issues, 20% non-discriminating). Add --weights flag to health command. Document formula in README with interpretation guide (what does 0.7 health mean?).","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:45.633823-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:45.633823-06:00","dependencies":[{"issue_id":"opencode-evals-9p7","depends_on_id":"opencode-evals-ac9","type":"blocks","created_at":"2026-01-11T20:52:04.781225-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-a86","title":"Add transcript viewer command","description":"Add 'opencode-eval view <transcript.jsonl>' command with rich formatting: syntax highlighting for code, collapsible sections for tool calls, color-coded events. Support both terminal output and HTML export. Make transcript reading effortless.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:19.357718-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:19.357718-06:00","dependencies":[{"issue_id":"opencode-evals-a86","depends_on_id":"opencode-evals-bpj","type":"blocks","created_at":"2026-01-11T20:51:37.235408-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-a91","title":"Improve documentation with Why and Workflows","description":"Add to README: (1) 'Why Evals?' section showing cost of not having evals, (2) 'Eval-First Development' workflow guide with examples, (3) Before/after examples of eval-driven development. Emphasize compounding value over time.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:27.80601-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:27.80601-06:00","dependencies":[{"issue_id":"opencode-evals-a91","depends_on_id":"opencode-evals-bpj","type":"blocks","created_at":"2026-01-11T20:51:37.510524-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-ac9","title":"Phase 7: Polish & Refinements (Nice-to-Have)","description":"Advanced features and optimizations: adaptive rate limiting, enhanced log parsing, configurable scoring, and interactive HTML reports.","status":"open","priority":2,"issue_type":"epic","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:29.330168-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:50:29.330168-06:00","dependencies":[{"issue_id":"opencode-evals-ac9","depends_on_id":"opencode-evals-c3r","type":"blocks","created_at":"2026-01-11T20:50:41.993425-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-ba0","title":"Add partial credit scoring system","description":"Allow graders to return partial credit (0.0-1.0) instead of binary pass/fail. Update Feedback type with weighted scoring. Combine multiple grader scores with configurable weights. Report breakdown by grader.","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:30.715213-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:41:14.472001-06:00","closed_at":"2026-01-11T19:41:14.472001-06:00","close_reason":"Implemented rubric-based grading, partial credit, and advanced code graders","dependencies":[{"issue_id":"opencode-evals-ba0","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:18.845822-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-bpj","title":"Phase 6: Developer Experience (UX Improvements)","description":"Make evals easier to use and understand. Add tooling for viewing transcripts, preset configurations, and better documentation emphasizing eval-first development.","status":"open","priority":1,"issue_type":"epic","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:28.183543-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:50:28.183543-06:00","dependencies":[{"issue_id":"opencode-evals-bpj","depends_on_id":"opencode-evals-c3r","type":"blocks","created_at":"2026-01-11T20:50:41.90081-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-bxb","title":"Add database state assertions","description":"Add assertion type for verifying database queries and state. Example: {type: 'database_query_result', query: 'SELECT * FROM users WHERE id=1', expected: {...}}. Support SQLite, PostgreSQL connection strings.","status":"open","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:53.182995-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:50:53.182995-06:00","dependencies":[{"issue_id":"opencode-evals-bxb","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.102914-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-c3r","title":"v2.0: Address Anthropic eval critique","status":"open","priority":1,"issue_type":"epic","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:19.085507-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:50:19.085507-06:00"}
{"id":"opencode-evals-d24","title":"Add haiku example for LLM judge (alternative to minimax)","description":"Currently using minimax-m2.1-free via OpenCode Zen as default. Add example showing how to use claude-3-haiku with ANTHROPIC_API_KEY for users who prefer Anthropic models.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-10T18:23:14.550539-06:00","created_by":"emiller","updated_at":"2026-01-10T18:23:29.04847-06:00"}
{"id":"opencode-evals-d6f","title":"Add multi-trial execution support","description":"Add 'trials' config option to run each task N times. Implement trial isolation (clean sandbox per trial). Store results per trial. Default to 1 trial for backward compatibility, recommend 3-5 for non-deterministic agents.","status":"closed","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:23.247824-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:34:11.570321-06:00","closed_at":"2026-01-11T19:34:11.570321-06:00","close_reason":"Implemented multi-trial support, transcript saving, and pass@k metrics"}
{"id":"opencode-evals-dv2","title":"Add HTTP/API call assertions","description":"Add assertion types for verifying HTTP requests made. Examples: {type: 'http_request_made', url: string, method: string}, {type: 'api_called', endpoint: string, body?: any}. Requires capturing network traffic during eval runs.","status":"open","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:55.346431-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:50:55.346431-06:00","dependencies":[{"issue_id":"opencode-evals-dv2","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.20427-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-dxk","title":"Add transcript saving and analysis","description":"Save full conversation transcripts per trial (JSONL format). Add transcript-based metrics: token efficiency, tool call patterns, conversation flow analysis. Detect anti-patterns (infinite loops, redundant calls, premature conclusions).","status":"closed","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:27.148192-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:34:11.571535-06:00","closed_at":"2026-01-11T19:34:11.571535-06:00","close_reason":"Implemented multi-trial support, transcript saving, and pass@k metrics"}
{"id":"opencode-evals-e2i","title":"Implement rubric-based grading","description":"Replace simple 'criteria' string with structured rubrics. Each rubric item has: name, description, weight, scoring levels (0-4 scale with descriptions). Aggregate weighted scores into final grade.","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:28.852553-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:41:14.470519-06:00","closed_at":"2026-01-11T19:41:14.470519-06:00","close_reason":"Implemented rubric-based grading, partial credit, and advanced code graders","dependencies":[{"issue_id":"opencode-evals-e2i","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:13.667348-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-e99","title":"Phase 5: Outcome-Based Evaluation (Critical Fixes)","description":"Close the 'outcome vs transcript' gap - the biggest conceptual issue from Anthropic critique. Focus on grading what was actually produced in the environment, not just what the agent said or which tools it called.","status":"in_progress","priority":0,"issue_type":"epic","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:26.848708-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T21:49:40.573404-06:00","dependencies":[{"issue_id":"opencode-evals-e99","depends_on_id":"opencode-evals-c3r","type":"blocks","created_at":"2026-01-11T20:50:41.80589-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-ez2","title":"Fix NDJSON tool_use event capture","description":"Tool calls show as 'undefined: {}' in eval results. The NDJSON format from 'opencode run --format json' has tool_use events with nested structure (part.tool, part.state.input/output) but current capture.ts may not be receiving these events. Need to verify event format and fix extraction.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-10T18:23:11.121475-06:00","created_by":"emiller","updated_at":"2026-01-10T20:14:16.701508-06:00","closed_at":"2026-01-10T20:14:16.701508-06:00","close_reason":"Investigated NDJSON tool_use event capture thoroughly. Tool calls are being captured correctly with proper names, args, output, and timestamps. Ran test evals that successfully captured tool events. No evidence of 'undefined: {}' issue in current codebase. Likely already resolved or based on outdated information."}
{"id":"opencode-evals-gy0","title":"Phase 3: Scale & Maintenance","description":"Add parallel execution, eval saturation detection, and maintenance tooling for running evals at scale.","status":"closed","priority":2,"issue_type":"feature","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:10.346451-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:14:34.011584-06:00","closed_at":"2026-01-11T20:14:34.011584-06:00","close_reason":"All Phase 3 features implemented: parallel execution, saturation detection, maintenance tooling"}
{"id":"opencode-evals-hjn","title":"Add production monitoring integration","description":"Convert production conversations to eval format. A/B testing support for prompts/models. Regression detection on new releases. Alert on quality degradation.","status":"closed","priority":3,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:53.000941-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:35:19.118533-06:00","closed_at":"2026-01-11T20:35:19.118533-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-hjn","depends_on_id":"opencode-evals-gy0","type":"blocks","created_at":"2026-01-11T19:18:15.035859-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-hri","title":"Add environment state assertions","description":"Add assertion for environment variables and system state. Examples: {type: 'environment_var', name: string, value: string}, {type: 'process_running', name: string}. Check actual environment state, not just what agent reported.","status":"closed","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:57.023268-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T22:08:35.64671-06:00","closed_at":"2026-01-11T22:08:35.64671-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-hri","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.294714-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-iu7","title":"Implement pass@k and pass^k metrics","description":"Add pass@k (at least 1 success in k trials) and pass^k (all k trials succeed) metrics. Update ExperimentSummary type. Add variance/consistency reporting across trials. Include confidence intervals.","status":"closed","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:25.530423-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:34:11.57238-06:00","closed_at":"2026-01-11T19:34:11.57238-06:00","close_reason":"Implemented multi-trial support, transcript saving, and pass@k metrics","dependencies":[{"issue_id":"opencode-evals-iu7","depends_on_id":"opencode-evals-d6f","type":"blocks","created_at":"2026-01-11T19:18:08.456566-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-j39","title":"Epic: opencode-evals - Lightweight evaluation framework for OpenCode plugins","description":"A bun-based evaluation framework that plugins include as a dev dependency. Supports code evaluators, LLM-as-judge, A/B variant comparison, and full JSON event stream capture.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-10T15:19:18.816115-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:21.770352-06:00","closed_at":"2026-01-10T15:28:21.770352-06:00","close_reason":"All phases complete: core framework, capture, multi-variant, LLM-as-judge, tests, docs"}
{"id":"opencode-evals-j39.1","title":"Phase 1: Foundation - Core types, sandbox, runner, code evaluator","description":"Get something working end-to-end:\n- [ ] Project setup (package.json, tsconfig.json)\n- [ ] Core types (types.ts) - Dataset, Example, EvalConfig, VariantConfig, Assertion, Experiment, Feedback\n- [ ] Sandbox creation (sandbox.ts) - temp dir + fixture management\n- [ ] Basic runner (runner.ts) - single variant, single example execution\n- [ ] Code evaluator (evaluators/code.ts) - file_exists, file_contains, file_not_contains\n- [ ] CLI skeleton (index.ts) - 'run' command with commander\n- [ ] One fixture (fixtures/empty/)\n- [ ] One example eval (examples/basic-assertions/)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T15:19:30.53431-06:00","created_by":"emiller","updated_at":"2026-01-10T15:24:56.611749-06:00","closed_at":"2026-01-10T15:24:56.611749-06:00","close_reason":"Phase 1 complete: core types, sandbox, capture, code evaluator, CLI, fixtures, example eval","dependencies":[{"issue_id":"opencode-evals-j39.1","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:30.553622-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.2","title":"Phase 2: Capture & Report - Event stream parsing, JSON/markdown output","description":"Make results useful:\n- [ ] Event stream capture (capture.ts) - parse 'opencode run --format json' output\n- [ ] Tool call extraction from events\n- [ ] Reporter (reporter.ts) - JSON output\n- [ ] Experiment summaries (pass_rate, avg_score, tokens, duration)\n- [ ] 'report' command for markdown output","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:31.261735-06:00","created_by":"emiller","updated_at":"2026-01-10T15:25:30.981047-06:00","closed_at":"2026-01-10T15:25:30.981047-06:00","close_reason":"Already implemented in Phase 1: capture.ts, reporter.ts, experiment summaries, report command","dependencies":[{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:31.265662-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39.1","type":"blocks","created_at":"2026-01-10T15:19:58.481169-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.2","depends_on_id":"opencode-evals-j39.7","type":"blocks","created_at":"2026-01-10T15:19:58.742399-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.3","title":"Phase 3: Multi-Variant - A/B testing between variants","description":"Enable A/B testing:\n- [ ] Multi-variant execution in runner\n- [ ] Variant-specific setup commands (e.g., 'jj git init' vs 'git init')\n- [ ] Compare command (compare two experiment results)\n- [ ] Side-by-side comparison reports","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:31.754678-06:00","created_by":"emiller","updated_at":"2026-01-10T15:25:50.516502-06:00","closed_at":"2026-01-10T15:25:50.516502-06:00","close_reason":"Already implemented: multi-variant runner, variant-specific setup, compare command, comparison reports","dependencies":[{"issue_id":"opencode-evals-j39.3","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:31.758796-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.3","depends_on_id":"opencode-evals-j39.2","type":"blocks","created_at":"2026-01-10T15:19:59.018729-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.4","title":"Phase 4: LLM-as-Judge - Advanced evaluation with criteria","description":"Advanced evaluation:\n- [ ] LLM judge evaluator (evaluators/llm-judge.ts)\n- [ ] Anthropic SDK integration (claude-3-haiku default)\n- [ ] Reference-free mode (no expected outputs needed)\n- [ ] Criteria evaluation with scoring and comments","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:33.809549-06:00","created_by":"emiller","updated_at":"2026-01-10T15:26:58.407477-06:00","closed_at":"2026-01-10T15:26:58.407477-06:00","close_reason":"LLM-as-judge evaluator complete with Anthropic SDK, reference-free mode, and example eval","dependencies":[{"issue_id":"opencode-evals-j39.4","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:33.813911-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.4","depends_on_id":"opencode-evals-j39.2","type":"blocks","created_at":"2026-01-10T15:19:59.25537-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.5","title":"Phase 5: Polish - Production readiness","description":"Make it production-ready:\n- [ ] Plugin resolution (node_modules + paths)\n- [ ] Dry-run mode (--dry-run flag)\n- [ ] Better error messages\n- [ ] Unit tests (test/)\n- [ ] More fixtures (git-repo/, simple-ts/)\n- [ ] Documentation (README.md)\n- [ ] Example evals for opencode-jj","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:36.427526-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.373623-06:00","closed_at":"2026-01-10T15:28:08.373623-06:00","close_reason":"Unit tests (21 passing), README docs, .gitignore complete","dependencies":[{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:36.431399-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39.3","type":"blocks","created_at":"2026-01-10T15:19:59.492714-06:00","created_by":"emiller"},{"issue_id":"opencode-evals-j39.5","depends_on_id":"opencode-evals-j39.4","type":"blocks","created_at":"2026-01-10T15:19:59.732293-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.6","title":"Design: Plugin resolution strategy","description":"Decide where plugins are resolved from when 'plugins: [\"jj-opencode\"]' is specified:\n1. Try node_modules/ of the plugin being tested\n2. Try ~/.config/opencode/plugin/ (global)\n3. Treat as path if contains '/' or '.'\n\nThis is currently unknown - need to determine based on how OpenCode loads plugins.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T15:19:43.743609-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.407373-06:00","closed_at":"2026-01-10T15:28:08.407373-06:00","close_reason":"Plugin resolution deferred - using path-based for now","dependencies":[{"issue_id":"opencode-evals-j39.6","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:43.745991-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.7","title":"Spike: Verify opencode run --format json event stream","description":"Run a test command to capture actual output from 'opencode run --format json'.\nNeed to understand:\n- Event structure/schema\n- How tool calls are represented\n- Token usage reporting\n- Exit codes and error handling\n\nThis blocks Phase 2 (capture.ts implementation).","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T15:19:46.405968-06:00","created_by":"emiller","updated_at":"2026-01-10T15:21:30.338037-06:00","closed_at":"2026-01-10T15:21:30.338037-06:00","close_reason":"Event stream format documented: NDJSON with step_start/tool_use/text/step_finish events","dependencies":[{"issue_id":"opencode-evals-j39.7","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:46.406687-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.8","title":"Design: Fixture management strategy","description":"Decide fixture approach (user chose: mix of both):\n- Basic fixtures committed in fixtures/ (empty, git-repo, simple-ts)\n- Complex fixtures generated on-demand via scripts\n\nNeed to implement both patterns.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:48.524477-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.439372-06:00","closed_at":"2026-01-10T15:28:08.439372-06:00","close_reason":"Mix of committed fixtures (empty, simple-ts) implemented","dependencies":[{"issue_id":"opencode-evals-j39.8","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:48.525565-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-j39.9","title":"Design: Error handling configuration","description":"User chose: all of the above as config options. Implement configurable error handling:\n- on_error: 'continue' | 'abort' | 'retry'\n- retry_count: number (default: 0)\n- timeout_ms: number (default: 120000)\n\nWhen eval fails (OpenCode crashes, timeout):\n- continue: mark as failed, continue other examples\n- abort: stop entire experiment\n- retry: retry up to retry_count times before failing","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T15:19:52.589546-06:00","created_by":"emiller","updated_at":"2026-01-10T15:28:08.470549-06:00","closed_at":"2026-01-10T15:28:08.470549-06:00","close_reason":"Error handling config implemented: on_error, retry_count, timeout_ms","dependencies":[{"issue_id":"opencode-evals-j39.9","depends_on_id":"opencode-evals-j39","type":"parent-child","created_at":"2026-01-10T15:19:52.592475-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-la8","title":"Add reference solution validation","description":"Add 'opencode-eval validate-references <dir>' command that runs reference solutions through graders to prove evals are solvable and graders work correctly. Fail CI if reference solutions don't pass. Add to pre-commit hooks.","status":"closed","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:02.061066-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T21:49:34.746975-06:00","closed_at":"2026-01-11T21:49:34.746975-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-la8","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.486068-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-lv2","title":"Plugin improvement: Auto-detect orphans and prompt recovery","description":"Based on orphan recovery eval results, improve plugin to: auto-detect orphaned commits on session start, proactively prompt user about recovery, integrate jj_recover_orphans into standard workflow.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-11T10:33:24.111003-06:00","created_by":"emiller","updated_at":"2026-01-11T10:58:05.853833-06:00","closed_at":"2026-01-11T10:58:05.853833-06:00","close_reason":"Implemented: immutable commit detection before edit, orphan warnings on gate open","dependencies":[{"issue_id":"opencode-evals-lv2","depends_on_id":"opencode-evals-xsz","type":"blocks","created_at":"2026-01-11T10:33:41.352275-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-mtt","title":"Plugin improvement: Better immutable commit guidance","description":"Based on immutable commit eval results, improve plugin to: provide clearer error messages when hitting immutable commits, suggest jj new workflow, potentially auto-detect and offer recovery.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-11T10:33:23.333769-06:00","created_by":"emiller","updated_at":"2026-01-11T10:58:05.824692-06:00","closed_at":"2026-01-11T10:58:05.824692-06:00","close_reason":"Implemented: immutable commit detection before edit, orphan warnings on gate open","dependencies":[{"issue_id":"opencode-evals-mtt","depends_on_id":"opencode-evals-6rw","type":"blocks","created_at":"2026-01-11T10:33:41.250589-06:00","created_by":"emiller"}]}
{"id":"opencode-evals-p7m","title":"Deprecate tool_call_sequence assertion","description":"Mark tool_call_sequence as anti-pattern. Add deprecation warning in types, update docs to explain why (agents find valid approaches designers didn't anticipate). Recommend outcome-based grading instead. Keep backward compatible but discourage use.","status":"closed","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:50:59.510069-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T21:49:34.671629-06:00","closed_at":"2026-01-11T21:49:34.671629-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-p7m","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.392404-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-qmx","title":"Add parallel execution support","description":"Run multiple trials/examples in parallel for faster iteration. Add concurrency config option. Implement worker pool with configurable parallelism. Handle resource contention (ports, files).","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:45.900192-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:56:48.336444-06:00","closed_at":"2026-01-11T19:56:48.336444-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-qmx","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:09.246243-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-s4e","title":"Improve LLM judge prompts","description":"Enhance llm-judge.ts prompts with: (1) Chain-of-thought reasoning before scoring, (2) Escape hatch for 'insufficient information' (score: null), (3) Few-shot examples for each score level, (4) Explicit anti-leniency instruction ('score 4 reserved for truly excellent work'). Update types to allow nullable scores.","status":"closed","priority":0,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:05.19754-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T22:22:56.273642-06:00","closed_at":"2026-01-11T22:22:56.273642-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-s4e","depends_on_id":"opencode-evals-e99","type":"blocks","created_at":"2026-01-11T20:51:16.57942-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-saj","title":"Add eval saturation detection","description":"Warn when eval pass rate exceeds 95% (eval may be too easy). Track pass rate over time. Suggest adding harder cases. Flag tasks that always pass/fail (not discriminating).","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:47.823488-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:56:48.354549-06:00","closed_at":"2026-01-11T19:56:48.354549-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-saj","depends_on_id":"opencode-evals-36c","type":"blocks","created_at":"2026-01-11T19:18:14.430454-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-smw","title":"Add human grading workflow","description":"Support human-in-the-loop grading for calibration. Export tasks for human review. Import human grades. Track inter-rater agreement. Use human grades to calibrate LLM judges.","status":"closed","priority":3,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:51.614445-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:35:19.047232-06:00","closed_at":"2026-01-11T20:35:19.047232-06:00","close_reason":"Closed","dependencies":[{"issue_id":"opencode-evals-smw","depends_on_id":"opencode-evals-gy0","type":"blocks","created_at":"2026-01-11T19:18:09.857893-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-tf4","title":"HTML report generation with interactive transcripts","description":"Generate HTML reports from experiments with: (1) Interactive transcripts (collapsible sections), (2) Syntax highlighted code blocks, (3) Pass/fail visualization, (4) Diff view for file changes. Add --format html to report command. Link transcripts from failure summaries.","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:47.925453-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:47.925453-06:00","dependencies":[{"issue_id":"opencode-evals-tf4","depends_on_id":"opencode-evals-ac9","type":"blocks","created_at":"2026-01-11T20:52:04.886559-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-tyu","title":"Add capability vs regression tagging","description":"Add eval_type field to Example: 'capability' | 'regression'. Separate reporting (capability = improving, regression = protecting). Different saturation thresholds (capability OK at 30%, regression should be >95%). Update health command to show both types.","status":"open","priority":1,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:24.827608-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:24.827608-06:00","dependencies":[{"issue_id":"opencode-evals-tyu","depends_on_id":"opencode-evals-bpj","type":"blocks","created_at":"2026-01-11T20:51:37.425187-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-v27","title":"Add advanced code graders","description":"Add static analysis graders: lint errors, type errors, security issues. Add performance metrics: execution time, token count per task. Add tool call sequence validation (order matters, not just presence). Add state verification beyond files (DB state, API calls mock).","status":"closed","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T19:17:32.434905-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T19:41:14.473268-06:00","closed_at":"2026-01-11T19:41:14.473268-06:00","close_reason":"Implemented rubric-based grading, partial credit, and advanced code graders","dependencies":[{"issue_id":"opencode-evals-v27","depends_on_id":"opencode-evals-79c","type":"blocks","created_at":"2026-01-11T19:18:24.026652-06:00","created_by":"Edmund Miller"}]}
{"id":"opencode-evals-xsz","title":"Create eval: Orphan detection and recovery","description":"Design synthetic eval testing agent detection and recovery of orphaned commits. Based on session analysis: 536 orphan mentions but only 1 jj_recover_orphans call. Success criteria: agent notices orphans in jj log, calls recovery tool, verifies changes restored.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-11T10:33:22.452312-06:00","created_by":"emiller","updated_at":"2026-01-11T10:36:00.626873-06:00","closed_at":"2026-01-11T10:36:00.626873-06:00","close_reason":"Created orphan-recovery.eval.json with 2 scenarios. Setup creates orphaned commits by starting fresh from root. Tests agent detection of orphans and use of jj_recover_orphans tool."}
{"id":"opencode-evals-zad","title":"Grader validation by eval type","description":"Improve grader validation to handle capability vs regression evals differently. For regression: flag if always fails (suspicious). For capability: only flag if grader disagrees with other graders <50% of time. Don't flag 'always fails' as broken for capability evals (might be testing hard features).","status":"open","priority":2,"issue_type":"task","owner":"git@edmundmiller.dev","created_at":"2026-01-11T20:51:56.725735-06:00","created_by":"Edmund Miller","updated_at":"2026-01-11T20:51:56.725735-06:00","dependencies":[{"issue_id":"opencode-evals-zad","depends_on_id":"opencode-evals-ac9","type":"blocks","created_at":"2026-01-11T20:52:04.992087-06:00","created_by":"Edmund Miller"}]}
